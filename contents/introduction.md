---
layout: contents
title: Introduction
---

Our community continues to explore the opportunities offered by machine learning technologies and expand the range of applications for which they are used. While we welcome the potential of these tools, we need to pay close attention to the significant risks that unconsidered deployment of these tools in the extremely complex contexts in which DRM is undertaken may create. Significant attention is currently being given by academics, journalists, and the public to questions of the ethics and bias of AI systems across a variety of domains including facial recognition (Keyes 2018), automated weaponry (Suchman et al 2016), search (Noble 2018), and criminal justice (Eubanks 2018). Despite significant potential for negative impacts of these tools in disaster risk management, our domain has not given these issues as much attention as other domains.

Some example of specific issues that might be concerns as a direct result of improper use of machine learning include:

* Perpetuating and aggravating societal inequalities through use of biased datasets
* Aggravating privacy and security concerns in Fragility Conflict and Violence settings through combination of previously distinct datasets
* Limiting opportunities for public participation in disaster risk management due to increased complexity of data products
* Reducing the role of expert judgement is data and modeling tasks in turn increasing probability of error or misuse.
* Hype, and availability of private sector funding for artificial intelligence technology in DRM, leads to overstatement of the capacities of these tools and the deployment of untested approaches in safety-critical scenarios

These are risks that need to be weighed seriously against the potential benefits before introducing new technologies into disaster information systems. While there are some relevant guidelines being produced in adjacent domains, the conversation is still evolving. In some cases, like facial recognition, experts have begun to recommend not using it all and they have been banned in a number of jurisdictions. It is too early to know how this debate will play out in the field of disaster risk management so it is worth proceeding with caution.

There are many ways by which, as we will discuss, through technical means as well as improved project design and management, machine learning projects can be more responsibly developed and applied. However, we will also note some of these issues go deeper than machine learning, and are rooted in how we collect disaster risk and impact data, and how we design DRM projects more broadly. Here the heightened focus on the social impacts of AI tools offer us an opportunity to draw attention to some of these questions. We address this in Section 4.